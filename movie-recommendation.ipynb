{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = '5g'\n",
    "spark = SparkSession.builder.appName('movie-recommendation')\\\n",
    "        .config('spark.executor.memory', MAX_MEMORY)\\\n",
    "        .config('spark.driver.memory', MAX_MEMORY)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_file = r'./data/ml-25m/ratings.csv'\n",
    "rating_df = spark.read.csv(rating_file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    296|   5.0|1147880044|\n",
      "|     1|    306|   3.5|1147868817|\n",
      "|     1|    307|   5.0|1147868828|\n",
      "|     1|    665|   5.0|1147878820|\n",
      "|     1|    899|   3.5|1147868510|\n",
      "|     1|   1088|   4.0|1147868495|\n",
      "|     1|   1175|   3.5|1147868826|\n",
      "|     1|   1217|   3.5|1147878326|\n",
      "|     1|   1237|   5.0|1147868839|\n",
      "|     1|   1250|   4.0|1147868414|\n",
      "|     1|   1260|   3.5|1147877857|\n",
      "|     1|   1653|   4.0|1147868097|\n",
      "|     1|   2011|   2.5|1147868079|\n",
      "|     1|   2012|   2.5|1147868068|\n",
      "|     1|   2068|   2.5|1147869044|\n",
      "|     1|   2161|   3.5|1147868609|\n",
      "|     1|   2351|   4.5|1147877957|\n",
      "|     1|   2573|   4.0|1147878923|\n",
      "|     1|   2632|   5.0|1147878248|\n",
      "|     1|   2692|   5.0|1147869100|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = rating_df.select(['userid','movieid','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userid: integer (nullable = true)\n",
      " |-- movieid: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|          25000095|\n",
      "|   mean| 3.533854451353085|\n",
      "| stddev|1.0607439611423508|\n",
      "|    min|               0.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.select('rating').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = rating_df.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaWrapper.__del__ at 0x076FACD0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\", line 39, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'ALS' object has no attribute '_java_obj'\n"
     ]
    }
   ],
   "source": [
    "als = ALS(\n",
    "    maxIter=5,\n",
    "    regParam=0.1,\n",
    "    userCol='userid',\n",
    "    itemCol='movieid',\n",
    "    ratingCol='rating',\n",
    "    coldStartStrategy='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userid|movieid|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   101|   8638|   5.0| 3.5119193|\n",
      "|   155|   1580|   2.5| 3.4675193|\n",
      "|   243|   1580|   3.0| 2.6661637|\n",
      "|   322|    463|   3.0| 3.2045796|\n",
      "|   472|   1088|   4.0| 3.4170225|\n",
      "|   472|   3918|   3.0| 2.3723238|\n",
      "|   497|   2366|   4.0| 3.8124385|\n",
      "|   501|   1580|   5.0|   3.87407|\n",
      "|   597|   2142|   2.0| 3.2140796|\n",
      "|   606|   4519|   4.0| 3.9513927|\n",
      "|   606|  68135|   3.5|  3.871873|\n",
      "|   626|   2122|   2.0|  2.243652|\n",
      "|   626|   2866|   3.0| 3.3826358|\n",
      "|   626|   3175|   4.0|  3.450072|\n",
      "|   626|   3997|   2.0|   2.11784|\n",
      "|   626|  36525|   4.0| 3.3286457|\n",
      "|   633|   1591|   5.0| 3.4640694|\n",
      "|   772|    471|   4.0|  3.476862|\n",
      "|   772|   1591|   1.0| 2.0172691|\n",
      "|   772|   1645|   3.0| 2.9905553|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|            rating|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           4995895|           4995895|\n",
      "|   mean|3.5338175642202247| 3.403473807382258|\n",
      "| stddev| 1.060629769668916|0.6402685908998172|\n",
      "|    min|               0.5|        -1.5802333|\n",
      "|    max|               5.0|          6.749661|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('rating', 'prediction').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8131680389985763\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userid|     recommendations|\n",
      "+------+--------------------+\n",
      "|    26|[{203086, 5.84763...|\n",
      "|    27|[{177411, 6.34608...|\n",
      "|    28|[{194434, 7.45642...|\n",
      "|    31|[{194334, 3.85096...|\n",
      "|    34|[{194434, 5.57265...|\n",
      "|    44|[{194434, 6.81767...|\n",
      "|    53|[{194334, 7.03597...|\n",
      "|    65|[{194434, 6.13258...|\n",
      "|    76|[{203086, 6.17230...|\n",
      "|    78|[{203086, 6.74651...|\n",
      "|    81|[{159761, 5.21492...|\n",
      "|    85|[{205453, 5.53288...|\n",
      "|   101|[{203086, 5.42073...|\n",
      "|   103|[{203086, 5.55319...|\n",
      "|   108|[{194434, 5.53796...|\n",
      "|   115|[{203086, 6.22221...|\n",
      "|   126|[{203086, 6.54823...|\n",
      "|   133|[{203086, 5.15062...|\n",
      "|   137|[{203086, 5.58885...|\n",
      "|   148|[{194434, 5.96479...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.recommendForAllUsers(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieid|     recommendations|\n",
      "+-------+--------------------+\n",
      "|     12|[{87426, 4.96737}...|\n",
      "|     26|[{66365, 5.141595...|\n",
      "|     27|[{30897, 5.297116...|\n",
      "|     28|[{58082, 5.411728...|\n",
      "|     31|[{143282, 5.20534...|\n",
      "|     34|[{128562, 5.70376...|\n",
      "|     44|[{87426, 5.070844...|\n",
      "|     53|[{138914, 5.28260...|\n",
      "|     65|[{87426, 4.952166...|\n",
      "|     76|[{87426, 5.166475...|\n",
      "|     78|[{149507, 4.71001...|\n",
      "|     81|[{7629, 4.839836}...|\n",
      "|     85|[{48436, 4.926748...|\n",
      "|    101|[{105801, 4.95114...|\n",
      "|    103|[{26659, 5.075937...|\n",
      "|    108|[{86709, 5.558506...|\n",
      "|    115|[{54404, 5.565475...|\n",
      "|    126|[{86668, 4.488641...|\n",
      "|    133|[{108346, 5.08828...|\n",
      "|    137|[{113441, 5.17785...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.recommendForAllItems(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userid|\n",
      "+------+\n",
      "|    10|\n",
      "|    40|\n",
      "|    70|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "user_list = [10, 40, 70]\n",
    "users_df = spark.createDataFrame(user_list, IntegerType()).toDF('userid')\n",
    "\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_recs = model.recommendForUserSubset(users_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_list = user_recs.collect()[0].recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|movieid|            rating|\n",
      "+-------+------------------+\n",
      "| 194434| 6.367295742034912|\n",
      "| 203086|6.2253618240356445|\n",
      "| 203882|   6.0559983253479|\n",
      "| 151989| 5.888882637023926|\n",
      "| 183947| 5.876765251159668|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recs_df = spark.createDataFrame(movies_list)\n",
    "recs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_file = './data/ml-25m/movies.csv'\n",
    "movies_df = spark.read.csv(movies_file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_df.createOrReplaceTempView('recommendations')\n",
    "movies_df.createOrReplaceTempView('movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|movieId|           title|              genres|\n",
      "+-------+----------------+--------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|\n",
      "+-------+----------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+-------+------------------+\n",
      "|movieId|               title|            genres|movieid|            rating|\n",
      "+-------+--------------------+------------------+-------+------------------+\n",
      "| 194434|   Adrenaline (1990)|(no genres listed)| 194434| 6.367295742034912|\n",
      "| 203086|Truth and Justice...|             Drama| 203086|6.2253618240356445|\n",
      "| 203882|Dead in the Water...|            Horror| 203882|   6.0559983253479|\n",
      "| 151989|    The Thorn (1971)|            Comedy| 151989| 5.888882637023926|\n",
      "| 183947|NOFX Backstage Pa...|(no genres listed)| 183947| 5.876765251159668|\n",
      "+-------+--------------------+------------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT *\n",
    "FROM \n",
    "    movies JOIN recommendations\n",
    "    ON movies.movieId = recommendations.movieid\n",
    "ORDER BY\n",
    "    rating desc\n",
    "'''\n",
    "recommended_movies = spark.sql(query)\n",
    "recommended_movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, num_recs):\n",
    "    users_df = spark.createDataFrame([user_id], IntegerType()).toDF('userid')\n",
    "    user_recs_df = model.recommendForUserSubset(users_df, num_recs)\n",
    "    \n",
    "    recs_list = user_recs_df.collect()[0].recommendations\n",
    "    recs_df = spark.createDataFrame(recs_list)\n",
    "    recommended_movies = spark.sql(query)\n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = get_recommendations(400, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
